{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart - Library Walkthrough\n",
    "\n",
    "## Main Features\n",
    "- Preset neural network models that each have a defined type of behaviour, such as conflicting features.\n",
    "- A dataset with the corresponding type of behaviour.\n",
    "- Pipelines for evaluating the performance of explanation methods, across multiple datasets and neural networks.\n",
    "- The pipelines can support custom explanation methods, evaluation metrics, models, and datasets\n",
    "- Trainable models are also supported along with a lightweight trainer helper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets And Neural Network Models\n",
    "\n",
    "Each Dataset has a corresponding preset neural network model, i.e. the weights have been explicitly defined rather than learned through training.\n",
    "\n",
    "List of behaviour types:\n",
    "- Continuous Features\n",
    "- Synthetic Cancellation\n",
    "- Pertinent Negative\n",
    "- Interacting Features\n",
    "- Shattered Gradients\n",
    "- Uncertainty Model\n",
    "- Boolean Formulas\n",
    "\n",
    "There is also the *Dynamic Neural Network* model that is trainable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152,\n",
      "         0.3223, -1.2633])\n",
      "y_true: tensor(-0.8077)\n",
      "context: {'ground_truth_attribute': tensor([ 1.0742, -0.7191, -0.0815,  0.1232,  0.2753,  0.5861, -0.2325, -1.2830,\n",
      "        -0.1876, -0.3630])}\n"
     ]
    }
   ],
   "source": [
    "# import all models and datasets\n",
    "from xaiunits.model import *\n",
    "from xaiunits.datagenerator import *\n",
    "\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(linewidth=10000)\n",
    "\n",
    "# suppose we want to experiment on a dataset with continuous features\n",
    "cont_dataset = WeightedFeaturesDataset(n_features=10, n_samples=500)\n",
    "\n",
    "# Examining one datapoint from the dataset\n",
    "x, y_true, context = cont_dataset[0]\n",
    "print(\"x:\", x)\n",
    "print(\"y_true:\", y_true)\n",
    "print(\"context:\", context) # context is a dict that (for most datasets) contains \"ground_truth_attribute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: tensor([-0.8077], grad_fn=<SqueezeBackward4>)\n",
      "y_pred: tensor([-0.8077], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "# Each dataset has an associated model type\n",
    "cont_model = ContinuousFeaturesNN(n_features=cont_dataset.n_features, weights = cont_dataset.weights)\n",
    "y_pred = cont_model(x)\n",
    "print(\"y_pred:\", y_pred)\n",
    "\n",
    "# It is possible to get this model directly from the data generator, so that the model is always consistent with the data\n",
    "cont_model = cont_dataset.generate_model()\n",
    "y_pred = cont_model(x)\n",
    "print(\"y_pred:\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run our own trained model. To do so, we can utilise the AutoTrainer we have implemented that builds upon the *lightning* package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for training\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data, val_data, test_data = cont_dataset.split([0.7, 0.15, 0.15])\n",
    "\n",
    "train_loader = DataLoader([data[:2] for data in train_data])\n",
    "val_loader = DataLoader([data[:2] for data in val_data])\n",
    "test_loader = DataLoader([data[:2] for data in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "n_features = 10\n",
    "model_arch = [{\"type\": \"Linear\", \"in_features\": n_features, \"out_features\": 32},\n",
    "    {\"type\": \"ReLU\"},\n",
    "    {\"type\": \"Linear\", \"in_features\": 32, \"out_features\": 8},\n",
    "    {\"type\": \"ReLU\"},\n",
    "    {\"type\": \"Linear\", \"in_features\": 8, \"out_features\": 8},\n",
    "    {\"type\": \"ReLU\"},\n",
    "    {\"type\": \"Linear\", \"in_features\": 8, \"out_features\": 1},\n",
    "]\n",
    "trained_model = DynamicNN(model_arch)\n",
    "\n",
    "\n",
    "loss = torch.nn.functional.mse_loss\n",
    "optim = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# define the trainer\n",
    "from xaiunits.trainer.trainer import AutoTrainer\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "lightning_linear_model = AutoTrainer(trained_model, loss, optim)\n",
    "trainer = L.Trainer(\n",
    "    min_epochs=5,\n",
    "    max_epochs=50,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=True)],\n",
    "    enable_progress_bar=False # Lightning progress bar displays poorly in jupyter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "trainer.fit(\n",
    "    model=lightning_linear_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")\n",
    "\n",
    "# test results after training\n",
    "trainer.test(lightning_linear_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "We want to apply attribution methods to our model. Any of the existing methods in *Captum* are supported as well as custom attribution methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import InputXGradient, IntegratedGradients, Lime\n",
    "from xaiunits.methods.methods_wrapper import wrap_method\n",
    "\n",
    "# List out the evaluation methods we want to use\n",
    "xmethods = [\n",
    "        InputXGradient,\n",
    "        IntegratedGradients,\n",
    "        Lime,\n",
    "    ]\n",
    "\n",
    "# If we want to pass non-default parameters to the attribution method, we use wrap_method to pre-load these parameters\n",
    "wrapped_method = wrap_method(IntegratedGradients, other_inputs={\"n_steps\": 25})\n",
    "xmethods.append(wrapped_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "Our goal is to evaluate how well each attribution method performs on different types of model and data. The metric (e.g. infidelity) provides a performance score.\n",
    "\n",
    "We support metrics from *Captum* and custom metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.metrics import sensitivity_max, infidelity\n",
    "from xaiunits.metrics import wrap_metric\n",
    "\n",
    "# We have wrap_metric to pre-load parameters into the metric, similar to wrap_method\n",
    "metrics = [\n",
    "    wrap_metric(sensitivity_max),\n",
    "    wrap_metric(infidelity, perturb_func=cont_dataset.perturb_function(), normalize=True),\n",
    "]\n",
    "# we can define a custom perturb function, or each dataset comes with a standard perturb function\n",
    "\n",
    "# Another common metric is the RMSE between the attributions and the ground truth context (when ground truth is available)\n",
    "# Note the usage of out_processing in the wrap_metric below, which allows us to pre-load arbitrary processing\n",
    "# In this case we want to convert the torch MSE to RMSE\n",
    "rmse_metric = wrap_metric(\n",
    "    torch.nn.functional.mse_loss, \n",
    "    out_processing=lambda x: torch.sqrt(torch.sum(x, dim=1)),\n",
    "    )\n",
    "metrics.append(rmse_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "\n",
    "There are the 2 kinds of pipeline we have created:\n",
    "\n",
    "- Pipeline\n",
    "- ExperimentPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline (Standard)\n",
    "- Allows running experiments on any number of models and datasets (assuming that they are all compatible).\n",
    "- Runs experiments over multiple seeds for the different explanation methods (useful when there is non-determinism)\n",
    "- Any number of explanation methods and evaluation metrics are supported\n",
    "- Aggregates the results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                             mean             \\\n",
      "model                                        ContinuousFeaturesNN              \n",
      "metric                                                  attr_time infidelity   \n",
      "trial_group_name method                                                        \n",
      "test             InputXGradient                             0.009  2.811e-04   \n",
      "                 IntegratedGradients                        0.325  2.811e-04   \n",
      "                 Lime                                       5.617  2.867e-04   \n",
      "                 wrapper_IntegratedGradients                0.170  2.811e-04   \n",
      "\n",
      "                                                                         \\\n",
      "model                                                                     \n",
      "metric                                         mse_loss sensitivity_max   \n",
      "trial_group_name method                                                   \n",
      "test             InputXGradient               0.000e+00           0.017   \n",
      "                 IntegratedGradients          4.289e-08           0.017   \n",
      "                 Lime                         2.306e-01           0.200   \n",
      "                 wrapper_IntegratedGradients  4.289e-08           0.017   \n",
      "\n",
      "                                                                            \\\n",
      "model                                        DynamicNN                       \n",
      "metric                                       attr_time infidelity mse_loss   \n",
      "trial_group_name method                                                      \n",
      "test             InputXGradient                  0.019  2.868e-04    0.281   \n",
      "                 IntegratedGradients             0.402  2.858e-04    0.251   \n",
      "                 Lime                            7.647  2.924e-04    0.245   \n",
      "                 wrapper_IntegratedGradients     0.167  2.858e-04    0.251   \n",
      "\n",
      "                                                              \n",
      "model                                                         \n",
      "metric                                       sensitivity_max  \n",
      "trial_group_name method                                       \n",
      "test             InputXGradient                        0.046  \n",
      "                 IntegratedGradients                   0.020  \n",
      "                 Lime                                  0.213  \n",
      "                 wrapper_IntegratedGradients           0.020  \n"
     ]
    }
   ],
   "source": [
    "from xaiunits.pipeline import Pipeline\n",
    "\n",
    "models = [trained_model, cont_model]\n",
    "datasets = [cont_dataset]\n",
    "\n",
    "# Instatiate the pipeline with a list of models, datasets, xmethods, metrics, and seeds.\n",
    "# All combinations will be evaluated\n",
    "pipeline = Pipeline(models, datasets, xmethods, metrics, method_seeds=[10], name=\"test\")\n",
    "results = pipeline.run() # apply the explanation methods and evaluate them\n",
    "\n",
    "\n",
    "# Accessing Pipeline Results\n",
    "# You can directly access a dataframe of all the results\n",
    "df = results.data\n",
    "# However we generally suggest using the print_stats method, which has a lot of options for unpivoting the table\n",
    "df_by_method = results.print_stats(stat_funcs=['mean'], index=[\"trial_group_name\", 'method'], column_index=['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Class\n",
    "\n",
    "In our example the model is a regression model, so the target class is not important. But if we have a classification model then the target class is important for most explanation methods.\n",
    "\n",
    "The pipeline has a parameter `default_target` which should take one of four possible values:\n",
    "\n",
    "- \"y_labels\" which will use the true y labels as the target class\n",
    "- \"predicted_class\" uses the model prediction as the target, i.e. y=model(feature_inputs)\n",
    "- an integer, for a single target class which will be used for all datapoints\n",
    "- a tuple or tensor matching the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing Examples from the pipeline\n",
    "\n",
    "A useful parameter to understand why the scores are high or low is the pipeline parameter n_examples. This stores the n-best and n-worst peforming examples for each method/model/metric for further inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example(score=tensor(1.3339e-07, dtype=torch.float64), attribute=tensor([-2.0317,  0.3137, -0.2884, -0.5674, -0.5510, -0.5692, -0.5603, -1.1613,\n",
      "         0.6530, -0.1734], dtype=torch.float64), feature_inputs=tensor([ 2.1293,  0.5027, -0.8871,  1.9974, -1.6984, -0.6720, -0.7617, -1.9145,\n",
      "        -1.1218, -0.6036]), y_labels=tensor(-4.9359), target=None, context={'ground_truth_attribute': tensor([-2.0317,  0.3137, -0.2884, -0.5674, -0.5510, -0.5692, -0.5603, -1.1613,\n",
      "         0.6530, -0.1734])}, example_type='max')\n",
      "x: tensor([ 2.1293,  0.5027, -0.8871,  1.9974, -1.6984, -0.6720, -0.7617, -1.9145,\n",
      "        -1.1218, -0.6036])\n",
      "y_true: tensor(-4.9359)\n",
      "context: {'ground_truth_attribute': tensor([-2.0317,  0.3137, -0.2884, -0.5674, -0.5510, -0.5692, -0.5603, -1.1613,\n",
      "         0.6530, -0.1734])}\n",
      "attributions: tensor([-2.0317,  0.3137, -0.2884, -0.5674, -0.5510, -0.5692, -0.5603, -1.1613,\n",
      "         0.6530, -0.1734], dtype=torch.float64)\n",
      "metric_score: tensor(1.3339e-07, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# To demonstrate this, we set up a new pipeline using the n_examples parameter\n",
    "pipeline = Pipeline(models, datasets, xmethods, metrics, method_seeds=[10], n_examples=1)\n",
    "results = pipeline.run()\n",
    "# The key for the examples is first \"max\" or \"min\" for the high / low scoring examples\n",
    "# Then a tuple of (method, model, metric) to select the type of example, which returns a list of length n_examples\n",
    "all_max_examples = results.examples[\"max\"]\n",
    "# print(all_max_examples)\n",
    "example_list = all_max_examples[(\"IntegratedGradients\", \"ContinuousFeaturesNN\", \"mse_loss\")]\n",
    "max_example = example_list[-1]\n",
    "print(max_example)\n",
    "\n",
    "# the Example includes the the original feature_inputs, y_labels, and context\n",
    "print(\"x:\", max_example.feature_inputs)\n",
    "print(\"y_true:\", max_example.y_labels)\n",
    "print(\"context:\", max_example.context)\n",
    "\n",
    "# and the Example includes the attributions and the metric score\n",
    "print(\"attributions:\", max_example.attribute)\n",
    "print(\"metric_score:\", max_example.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment Pipeline\n",
    "- The ExperimentPipeline gives a systematic way for iterating over datasets with repeatable data seeds\n",
    "- Allows for trials run on different seeds for generating the data\n",
    "- Supports experiments that are wrapped with our Experiment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose we want to run experiments on these models\n",
    "pert_neg_model1 = PertinentNegativesDataset().generate_model()\n",
    "pert_neg_model2 = PertinentNegativesDataset(weight_range=(-10.0, 10.0)).generate_model()\n",
    "pert_neg_model3 = PertinentNegativesDataset(pn_weight_factor=200).generate_model()\n",
    "\n",
    "shatter_grad_model1 = ShatteredGradientsDataset().generate_model()\n",
    "shatter_grad_model2 = ShatteredGradientsDataset(discontinuity_ratios=[1.0, 2.0, -7.0, 9.5, -2.0]).generate_model()\n",
    "shatter_grad_model3 = ShatteredGradientsDataset(discontinuity_ratios=[60.45, -32.2, 23.1, 5.5, 12.0], bias=2.0).generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import DeepLift, ShapleyValueSampling, KernelShap, LRP\n",
    "\n",
    "xmethods2 = [\n",
    "    DeepLift,\n",
    "    ShapleyValueSampling,\n",
    "    KernelShap,\n",
    "    LRP    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xaiunits.pipeline import Experiment\n",
    "\n",
    "# we need to first wrap them as an Experiment instance\n",
    "# it is possible to just to give the class of the dataset and the data will be instantiated over different seeds during the experiment\n",
    "pert_neg_experiment = Experiment(PertinentNegativesDataset, \n",
    "                                 [pert_neg_model1, pert_neg_model2, pert_neg_model3],\n",
    "                                 xmethods2,\n",
    "                                 None, # Using default metric for evaluation \n",
    "                                 seeds=[3, 4],\n",
    "                                 method_seeds=[0, 11],\n",
    "                      )\n",
    "\n",
    "# Alternatively, an instantiated dataset can still be passed in\n",
    "shattered_grad_experiment = Experiment(ShatteredGradientsDataset(discontinuity_ratios=[1.0, 2.0, -7.0, 9.5, -2.0]), \n",
    "                                       [shatter_grad_model1, shatter_grad_model2, shatter_grad_model3],\n",
    "                                        xmethods2, \n",
    "                                        None,\n",
    "                                        seeds=[3, 4],\n",
    "                                        method_seeds=[0, 11],\n",
    "                            )\n",
    "\n",
    "# also can choose to pass in no model and allow the dataset to generate the corresponding model\n",
    "interacion_feat_experiment = Experiment(InteractingFeatureDataset, \n",
    "                                        None, \n",
    "                                        xmethods2, \n",
    "                                        None,\n",
    "                                        seeds=[3, 4],\n",
    "                                        method_seeds=[0, 11],\n",
    "                                        )\n",
    "\n",
    "# customisation to how the data is generated is also possible\n",
    "conflicting_experiment = Experiment(ConflictingDataset, \n",
    "                                    None,\n",
    "                                    xmethods2,\n",
    "                                    None, \n",
    "                                    seeds=[3, 4],\n",
    "                                    method_seeds=[0, 11],\n",
    "                                    data_params={\"n_samples\": 100, \"n_features\": 3, \"cancellation_likelihood\": 0.8},\n",
    "                      )\n",
    "\n",
    "experiments = [\n",
    "    pert_neg_experiment,\n",
    "    shattered_grad_experiment,\n",
    "    interacion_feat_experiment,\n",
    "    conflicting_experiment,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xaiunits.pipeline import ExperimentPipeline\n",
    "\n",
    "# instantiate the pipeline, run the attribution methods, then process and print the results\n",
    "exp_pipeline = ExperimentPipeline(experiments)\n",
    "exp_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                          mean  \\\n",
      "metric                                                               attr_time   \n",
      "data                      model                 method                           \n",
      "ConflictingDataset        ConflictingFeaturesNN DeepLift                 0.002   \n",
      "                                                KernelShap               0.396   \n",
      "                                                LRP                      0.002   \n",
      "                                                ShapleyValueSampling     0.039   \n",
      "InteractingFeatureDataset InteractingFeaturesNN DeepLift                 0.001   \n",
      "                                                KernelShap               0.195   \n",
      "                                                LRP                      0.001   \n",
      "                                                ShapleyValueSampling     0.008   \n",
      "PertinentNegativesDataset PertinentNN           DeepLift                 0.005   \n",
      "                                                KernelShap               0.140   \n",
      "                                                LRP                      0.003   \n",
      "                                                ShapleyValueSampling     0.038   \n",
      "ShatteredGradientsDataset ShatteredGradientsNN  DeepLift                 0.004   \n",
      "                                                KernelShap               1.138   \n",
      "                                                LRP                      0.003   \n",
      "                                                ShapleyValueSampling     0.060   \n",
      "\n",
      "                                                                                 \\\n",
      "metric                                                                 mse_loss   \n",
      "data                      model                 method                            \n",
      "ConflictingDataset        ConflictingFeaturesNN DeepLift              1.424e-01   \n",
      "                                                KernelShap            4.536e-02   \n",
      "                                                LRP                   1.424e-01   \n",
      "                                                ShapleyValueSampling  3.076e-02   \n",
      "InteractingFeatureDataset InteractingFeaturesNN DeepLift              0.000e+00   \n",
      "                                                KernelShap            9.243e-02   \n",
      "                                                LRP                   9.108e-16   \n",
      "                                                ShapleyValueSampling  6.905e-02   \n",
      "PertinentNegativesDataset PertinentNN           DeepLift              5.281e+01   \n",
      "                                                KernelShap            5.281e+01   \n",
      "                                                LRP                   6.219e+00   \n",
      "                                                ShapleyValueSampling  5.281e+01   \n",
      "ShatteredGradientsDataset ShatteredGradientsNN  DeepLift                    NaN   \n",
      "                                                KernelShap                  NaN   \n",
      "                                                LRP                         NaN   \n",
      "                                                ShapleyValueSampling        NaN   \n",
      "\n",
      "                                                                                      \\\n",
      "metric                                                               sensitivity_max   \n",
      "data                      model                 method                                 \n",
      "ConflictingDataset        ConflictingFeaturesNN DeepLift                         NaN   \n",
      "                                                KernelShap                       NaN   \n",
      "                                                LRP                              NaN   \n",
      "                                                ShapleyValueSampling             NaN   \n",
      "InteractingFeatureDataset InteractingFeaturesNN DeepLift                         NaN   \n",
      "                                                KernelShap                       NaN   \n",
      "                                                LRP                              NaN   \n",
      "                                                ShapleyValueSampling             NaN   \n",
      "PertinentNegativesDataset PertinentNN           DeepLift                         NaN   \n",
      "                                                KernelShap                       NaN   \n",
      "                                                LRP                              NaN   \n",
      "                                                ShapleyValueSampling             NaN   \n",
      "ShatteredGradientsDataset ShatteredGradientsNN  DeepLift                     114.367   \n",
      "                                                KernelShap                     3.910   \n",
      "                                                LRP                          114.367   \n",
      "                                                ShapleyValueSampling           1.184   \n",
      "\n",
      "                                                                            std  \\\n",
      "metric                                                                attr_time   \n",
      "data                      model                 method                            \n",
      "ConflictingDataset        ConflictingFeaturesNN DeepLift              1.672e-04   \n",
      "                                                KernelShap            2.000e-02   \n",
      "                                                LRP                   1.241e-04   \n",
      "                                                ShapleyValueSampling  6.651e-03   \n",
      "InteractingFeatureDataset InteractingFeaturesNN DeepLift              1.413e-04   \n",
      "                                                KernelShap            1.027e-02   \n",
      "                                                LRP                   1.705e-04   \n",
      "                                                ShapleyValueSampling  9.660e-05   \n",
      "PertinentNegativesDataset PertinentNN           DeepLift              1.013e-03   \n",
      "                                                KernelShap            8.938e-03   \n",
      "                                                LRP                   1.172e-04   \n",
      "                                                ShapleyValueSampling  2.957e-03   \n",
      "ShatteredGradientsDataset ShatteredGradientsNN  DeepLift              2.955e-04   \n",
      "                                                KernelShap            3.311e-02   \n",
      "                                                LRP                   2.350e-04   \n",
      "                                                ShapleyValueSampling  1.232e-03   \n",
      "\n",
      "                                                                                 \\\n",
      "metric                                                                 mse_loss   \n",
      "data                      model                 method                            \n",
      "ConflictingDataset        ConflictingFeaturesNN DeepLift              3.189e-02   \n",
      "                                                KernelShap            1.072e-02   \n",
      "                                                LRP                   3.189e-02   \n",
      "                                                ShapleyValueSampling  8.854e-03   \n",
      "InteractingFeatureDataset InteractingFeaturesNN DeepLift              0.000e+00   \n",
      "                                                KernelShap            6.608e-02   \n",
      "                                                LRP                   1.260e-17   \n",
      "                                                ShapleyValueSampling  6.044e-02   \n",
      "PertinentNegativesDataset PertinentNN           DeepLift              9.908e+00   \n",
      "                                                KernelShap            9.908e+00   \n",
      "                                                LRP                   2.821e-01   \n",
      "                                                ShapleyValueSampling  9.908e+00   \n",
      "ShatteredGradientsDataset ShatteredGradientsNN  DeepLift                    NaN   \n",
      "                                                KernelShap                  NaN   \n",
      "                                                LRP                         NaN   \n",
      "                                                ShapleyValueSampling        NaN   \n",
      "\n",
      "                                                                                      \n",
      "metric                                                               sensitivity_max  \n",
      "data                      model                 method                                \n",
      "ConflictingDataset        ConflictingFeaturesNN DeepLift                         NaN  \n",
      "                                                KernelShap                       NaN  \n",
      "                                                LRP                              NaN  \n",
      "                                                ShapleyValueSampling             NaN  \n",
      "InteractingFeatureDataset InteractingFeaturesNN DeepLift                         NaN  \n",
      "                                                KernelShap                       NaN  \n",
      "                                                LRP                              NaN  \n",
      "                                                ShapleyValueSampling             NaN  \n",
      "PertinentNegativesDataset PertinentNN           DeepLift                         NaN  \n",
      "                                                KernelShap                       NaN  \n",
      "                                                LRP                              NaN  \n",
      "                                                ShapleyValueSampling             NaN  \n",
      "ShatteredGradientsDataset ShatteredGradientsNN  DeepLift                      12.123  \n",
      "                                                KernelShap                     2.134  \n",
      "                                                LRP                           12.123  \n",
      "                                                ShapleyValueSampling           0.148  \n"
     ]
    }
   ],
   "source": [
    "df = exp_pipeline.results.print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
