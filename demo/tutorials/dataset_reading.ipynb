{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Conflicting Dataset}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the default dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from xaiunits.datagenerator import ConflictingDataset\n",
    "\n",
    "data = ConflictingDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to access the main attributes: \n",
    "* `n_features` being the number of features\n",
    "* `cancellation_features` being the indices of the features subject to cancellation\n",
    "* `cancellation_outcomes` being a binary tensor indicating whether each feature in each sample is canceled\n",
    "* `cancellation_samples` being a concatenation of samples with their cancellation outcomes\n",
    "* `cancellation_attributes` is the attribution of each feature considering the cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[0, 1]\n",
      "tensor([[0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [1, 1],\n",
      "        [0, 0]], dtype=torch.int32)\n",
      "tensor([[-1.1258, -1.1524,  0.0000,  1.0000],\n",
      "        [-0.2506, -0.4339,  1.0000,  0.0000],\n",
      "        [ 0.5988, -1.5551,  0.0000,  1.0000],\n",
      "        [-0.3414,  1.8530,  0.0000,  1.0000],\n",
      "        [ 0.4681, -0.1577,  1.0000,  1.0000],\n",
      "        [ 1.4437,  0.2660,  0.0000,  1.0000],\n",
      "        [ 1.3894,  1.5863,  0.0000,  0.0000],\n",
      "        [ 0.9463, -0.8437,  0.0000,  0.0000],\n",
      "        [ 0.9318,  1.2590,  1.0000,  1.0000],\n",
      "        [ 2.0050,  0.0537,  0.0000,  0.0000]])\n",
      "tensor([[ 0.0000, -0.8934],\n",
      "        [ 0.0467,  0.0000],\n",
      "        [ 0.0000, -1.2057],\n",
      "        [ 0.0000,  1.4366],\n",
      "        [-0.0872, -0.1223],\n",
      "        [ 0.0000,  0.2063],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [-0.1736,  0.9761],\n",
      "        [ 0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "print(data.n_features)\n",
    "print(data.cancellation_features)\n",
    "print(data.cancellation_outcomes)\n",
    "print(data.cancellation_samples)\n",
    "print(data.cancellation_attributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every dataset you can access the attributes and change them. If you change some attributes, other attributes may also need to be adapted accordingly. An example is shown below. If you change the cancellation features attributes, you need to update the `cancellation_outcomes`, `cancellation_samples`, `cancellation_attributions` attributes, as well as the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [0, 0],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0]], dtype=torch.int32)\n",
      "tensor([[-1.1258, -1.1524,  1.0000,  1.0000],\n",
      "        [-0.2506, -0.4339,  0.0000,  0.0000],\n",
      "        [ 0.5988, -1.5551,  1.0000,  1.0000],\n",
      "        [-0.3414,  1.8530,  1.0000,  1.0000],\n",
      "        [ 0.4681, -0.1577,  1.0000,  1.0000],\n",
      "        [ 1.4437,  0.2660,  1.0000,  0.0000],\n",
      "        [ 1.3894,  1.5863,  1.0000,  0.0000],\n",
      "        [ 0.9463, -0.8437,  1.0000,  0.0000],\n",
      "        [ 0.9318,  1.2590,  0.0000,  1.0000],\n",
      "        [ 2.0050,  0.0537,  1.0000,  0.0000]])\n",
      "tensor([[ 0.2098, -0.8934],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [-0.1116, -1.2057],\n",
      "        [ 0.0636,  1.4366],\n",
      "        [-0.0872, -0.1223],\n",
      "        [-0.2690,  0.0000],\n",
      "        [-0.2589,  0.0000],\n",
      "        [-0.1763,  0.0000],\n",
      "        [ 0.0000,  0.9761],\n",
      "        [-0.3736,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "data.cancellation_features = [1,0]\n",
    "data.weights = data._initialize_weights(data.weights, data.weight_range)[0]\n",
    "data.cancellation_outcomes = data._get_cancellations()\n",
    "data.cancellation_samples = data._get_cancellation_samples()\n",
    "data.cancellation_attributions = data._get_cancellation_attributions()\n",
    "print(data.cancellation_outcomes)\n",
    "print(data.cancellation_samples)\n",
    "print(data.cancellation_attributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every datasets have a `generate_model` method which generates the paired model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the corresponding model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xaiunits.model.conflicting.ConflictingFeaturesNN'>\n"
     ]
    }
   ],
   "source": [
    "model = data.generate_model()\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Pertinent Negative Dataset}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the default dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xaiunits.datagenerator import PertinentNegativesDataset\n",
    "\n",
    "data = PertinentNegativesDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, here are the attributes for this dataset:\n",
    "* `n_features` is the number of features\n",
    "* `weights` are the weights of the model\n",
    "* `pn_features` represents the indices of features to be considered as pertinent negatives\n",
    "* `pn_weight_factor` is the factor representing the enhance impact of pertinent negatives\n",
    "* `pn_zero_likelihood` represent the likelihood of a pertinent negative feature being set to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "tensor([-0.1646, -0.4578,  0.3846, -0.5923,  0.3666])\n",
      "[0]\n",
      "10\n",
      "0.5\n",
      "tensor([[ 0.0000, -1.1524, -0.2506, -0.4339,  0.8487],\n",
      "        [ 1.0000, -0.3160, -2.1152,  0.3223, -1.2633],\n",
      "        [ 0.0000,  0.3081,  0.1198,  1.2377,  1.1168],\n",
      "        [ 0.0000, -1.3527, -1.6959,  0.5667,  0.7935],\n",
      "        [ 1.0000, -1.5551, -0.3414,  1.8530,  0.7502],\n",
      "        [ 1.0000, -0.1734,  0.1835,  1.3894,  1.5863],\n",
      "        [ 0.0000, -0.8437, -0.6136,  0.0316,  1.0554],\n",
      "        [ 0.0000, -0.2303, -0.3918,  0.5433, -0.3952],\n",
      "        [ 0.0000, -0.4503,  1.5210,  3.4105, -1.5312],\n",
      "        [ 0.0000,  1.8197, -0.5515, -1.3253,  0.1886]])\n"
     ]
    }
   ],
   "source": [
    "print(data.n_features)\n",
    "print(data.weights)\n",
    "print(data.pn_features)\n",
    "print(data.pn_weight_factor)\n",
    "print(data.pn_zero_likelihood)\n",
    "\n",
    "print(data.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you change one of the previous attribute you then need to call the following method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000, -0.2506, -0.4339,  0.8487],\n",
      "        [ 1.0000,  1.0000, -2.1152,  0.3223, -1.2633],\n",
      "        [ 1.0000,  0.0000,  0.1198,  1.2377,  1.1168],\n",
      "        [ 1.0000,  1.0000, -1.6959,  0.5667,  0.7935],\n",
      "        [ 1.0000,  1.0000, -0.3414,  1.8530,  0.7502],\n",
      "        [ 1.0000,  1.0000,  0.1835,  1.3894,  1.5863],\n",
      "        [ 0.0000,  0.0000, -0.6136,  0.0316,  1.0554],\n",
      "        [ 1.0000,  0.0000, -0.3918,  0.5433, -0.3952],\n",
      "        [ 1.0000,  1.0000,  1.5210,  3.4105, -1.5312],\n",
      "        [ 1.0000,  1.0000, -0.5515, -1.3253,  0.1886]])\n"
     ]
    }
   ],
   "source": [
    "data.pn_features = [0,1]\n",
    "data.pn_weight_factor = 20\n",
    "\n",
    "data._initialize_zeros_for_PN()\n",
    "data._get_new_weighted_samples()\n",
    "\n",
    "\n",
    "print(data.samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the corresponding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xaiunits.model.pertinent_negative.PertinentNN'>\n"
     ]
    }
   ],
   "source": [
    "model = data.generate_model()\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Interacting Features Dataset}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xaiunits.datagenerator import InteractingFeatureDataset\n",
    "\n",
    "data = InteractingFeatureDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main attributes of the `InteractingFeatureDataset` include:\n",
    "* `n_features` is the number of features\n",
    "* `weights` represents the weights of the model\n",
    "* `interacting_features` represents the pairs of indices where the first index is the feature whose weight is influenced by the second categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[(0.44000208377838135, 0.8909304141998291), 0.330818772315979, (0.9996763467788696, 0.5186629295349121), 0.6216483116149902]\n",
      "[[1, 0], [3, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(data.n_features)\n",
    "print(data.weights)\n",
    "print(data.interacting_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the correspoding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xaiunits.model.interaction_features.InteractingFeaturesNN'>\n"
     ]
    }
   ],
   "source": [
    "model = data.generate_model()\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Uncertainty Aware Dataset}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xaiunits.datagenerator import UncertaintyAwareDataset\n",
    "\n",
    "data = UncertaintyAwareDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main attributes of the `UncertaintyAwareDataset` include:\n",
    "* `n_features` is the number of features\n",
    "* `weights` corresponds to the weights of the model\n",
    "* `common_features` represents the number of common features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "tensor([[1., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 1.]])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(data.n_features)\n",
    "print(data.weights)\n",
    "print(data.common_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you change any of the previous attributes, you can call the `_create_weights` method which adapt the weights accordingly to the number of common features. Set the weights to `None` in the input if you want the weights of dataset to be adapted. Otherwise you can just set the weight manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1.]])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "data.common_features = 3\n",
    "\n",
    "data.weights = data._create_weights(data.n_features, None, data.common_features)\n",
    "\n",
    "print(data.weights)\n",
    "print(data.common_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xaiunits.model.uncertainty_model.UncertaintyNN'>\n"
     ]
    }
   ],
   "source": [
    "model = data.generate_model()\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Shattered Gradient Dataset}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xaiunits.datagenerator import ShatteredGradientsDataset\n",
    "\n",
    "data = ShatteredGradientsDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the main attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main attributes of the `ShatteredGradientsDataset` include:\n",
    "* `n_features` represents the number of features\n",
    "* `discontinuity_ratios` is the ratio indicating feature discontinuity\n",
    "* `bias` is the bias value of the model\n",
    "* `act_fun` represents the activation function used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[-1, 4, -2, -5, -2]\n",
      "0.5\n",
      "ReLU()\n"
     ]
    }
   ],
   "source": [
    "print(data.n_features) \n",
    "print(data.discontinuity_ratios)\n",
    "print(data.bias)\n",
    "print(data.act_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xaiunits.datagenerator.shattered_grad.ShatteredGradientsDataset'>\n"
     ]
    }
   ],
   "source": [
    "data.generate_model()\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Boolean Formula Dataset}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the default dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we also need to define the initial atoms as well as the Boolean formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xaiunits.datagenerator import BooleanDataset\n",
    "\n",
    "from sympy import symbols\n",
    "\n",
    "x, y, z, a = symbols(\"x y z a\")\n",
    "k = (x & (y | ~z)) & (z | a)\n",
    "data = BooleanDataset(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the main attributes:\n",
    "* `atoms` being the atoms\n",
    "* `formula` being the boolean formula provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x & (a | z) & (y | ~z)\n",
      "(x, y, z, a)\n"
     ]
    }
   ],
   "source": [
    "print(data.formula)\n",
    "print(data.atoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Balanced Image Dataset}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the default dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xaiunits.datagenerator.image_generation import BalancedImageDataset\n",
    "\n",
    "data = BalancedImageDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main attributes of `BalancedImageDataset` are:\n",
    "\n",
    "* `backgrounds` is a list of specific backgrounds to use\n",
    "* `shapes` is a list of specific shapes\n",
    "* `shape_colors` is the default color(s) for shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blotchy_0083.jpg', 'lacelike_0065.jpg', 'lined_0086.jpg', 'stratified_0101.jpg', 'fibrous_0171.jpg']\n",
      "['heptagon', 'hexagon', 'rectangle', 'decagon', 'triangle', 'octagon', 'ellipse', 'pentagon', 'square', 'circle']\n",
      "[(0, 255, 0, 255)]\n"
     ]
    }
   ],
   "source": [
    "print(data.backgrounds)\n",
    "print(data.shapes)\n",
    "print(data.shape_colors)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can show an image given its tensor representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "x, y_label, context = data[0]\n",
    "data.show_image(x)\n",
    "print(y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we show another image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "x, y_label, context = data[3]\n",
    "data.show_image(x)\n",
    "print(y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Imbalanced Image Dataset}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is very similar to the previous one. But here imbalance refers to the fact that users can specify the percentage of dominant (background, foreground) pair versus other pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xaiunits.datagenerator.image_generation import ImbalancedImageDataset\n",
    "\n",
    "data = ImbalancedImageDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blotchy_0083.jpg', 'lacelike_0065.jpg', 'lined_0086.jpg', 'stratified_0101.jpg', 'fibrous_0171.jpg']\n",
      "['heptagon', 'hexagon', 'rectangle']\n",
      "[(255, 0, 0, 255)]\n"
     ]
    }
   ],
   "source": [
    "print(data.backgrounds)\n",
    "print(data.shapes)\n",
    "print(data.shape_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "x, y_label, context = data[0]\n",
    "data.show_image(x)\n",
    "print(y_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
